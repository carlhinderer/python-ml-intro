{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having discussed the fundamentals of supervised and unsupervised learning, and having explored a variety of machine learning algorithms, we will now dive more deeply into evaluating models and selecting parameters.\n",
    "\n",
    "We will focus on the supervised methods, regression and classification, as evaluating and selecting models in unsupervised learning is often a very qualitative process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our supervised models, so far we have split our dataset into a training set and a test set using the *train_test_split* function, built a model on the training set by calling the *fit* method, and evaluated it on the test set using the *score* method, which for classification computes the fraction of correctly classified samples. Here’s an example of that process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "from IPython.display import display\n",
    "import mglearn\n",
    "\n",
    "# Don't display deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a synthetic dataset\n",
    "X, y = make_blobs(random_state=0)\n",
    "\n",
    "# Split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Instantiate a model and fit it to the training set\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"Test set score: {:.2f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the reason we split our data into training and test sets is that we are interested in measuring how well our model generalizes to new, previously unseen data. We are not interested in how well our model fit the training set, but rather in how well it can make predictions for data that was not observed during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we will expand on two aspects of this evaluation. We will first introduce *cross-validation*, a more robust way to assess generalization performance, and discuss methods to evaluate classification and regression performance that go beyond the default measures of accuracy and R2 provided by the score method.\n",
    "\n",
    "We will also discuss *grid search*, an effective method for adjusting the parameters in supervised models for the best generalization performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Cross-validation* is a statistical method of evaluating generalization performance that is more stable and thorough than using a split into a training and a test set. In cross-validation, the data is instead split repeatedly and multiple models are trained. \n",
    "\n",
    "The most commonly used version of cross-validation is *k-fold cross-validation*, where k is a user-specified number, usually 5 or 10. When performing five-fold cross-validation, the data is first partitioned into five parts of (approximately) equal size, called *folds*. \n",
    "\n",
    "Next, a sequence of models is trained. The first model is trained using the first fold as the test set, and the remaining folds (2–5) are used as the training set. The model is built using the data in folds 2–5, and then the accuracy is evaluated on fold 1. Then another model is built, this time using fold 2 as the test set and the data in folds 1, 3, 4, and 5 as the training set. This process is repeated using folds 3, 4, and 5 as test sets. For each of these five splits of the data into training and test sets, we compute the accuracy. In the end, we have collected five accuracy values. \n",
    "\n",
    "The process is illustrated here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mglearn.plots.plot_cross_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, the first fifth of the data is the first fold, the second fifth of the data is the second fold, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is implemented in *scikit-learn* using the *cross_val_score* function from the *model_selection* module. The parameters of the *cross_val_score* function are the model we want to evaluate, the training data, and the ground-truth labels. Let’s evaluate *LogisticRegression* on the *iris* dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.96078431 0.92156863 0.95833333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iris = load_iris()\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "scores = cross_val_score(logreg, iris.data, iris.target)\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, *cross_val_score* performed three-fold cross-validation and therefore returned three scores. By default, *cross_val_score* performs three-fold cross-validation in earlier versions of scikit-learn, and will perform five-fold cross-validation by default (starting with scikit-learn 0.22). We can change the number of folds used by changing the *cv* parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1.         0.96666667 0.93333333 0.9        1.        ]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=5)\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s recommended to use at least five-fold cross-validation. A common way to summarize the cross-validation accuracy is to compute the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the mean cross-validation we can conclude that we expect the model to be around 96% accurate on average. Looking at all five scores produced by the five-fold cross-validation, we can also conclude that there is a relatively high variance in the accuracy between folds, ranging from 100% accuracy to 90% accuracy. This could imply that the model is very dependent on the particular folds used for training, but it could also just be a consequence of the small size of the dataset. \n",
    "\n",
    "There is a second function you can use for cross-validation, called *cross_validate*. It has a similar interface to *cross_val_score*, but returns a dictionary containing training and test times (and optionally the training score, in addition to the test scores) for each split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00177312, 0.00174832, 0.00123787, 0.00122571, 0.00121379]),\n",
       " 'score_time': array([0.00057912, 0.00043249, 0.00042343, 0.00039077, 0.00038838]),\n",
       " 'test_score': array([1.        , 0.96666667, 0.93333333, 0.9       , 1.        ]),\n",
       " 'train_score': array([0.95      , 0.96666667, 0.96666667, 0.975     , 0.95833333])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "res = cross_validate(logreg, iris.data, iris.target, cv=5, return_train_score=True)\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas, we can nicely display these results and compute summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.001773    0.000579    1.000000     0.950000\n",
       "1  0.001748    0.000432    0.966667     0.966667\n",
       "2  0.001238    0.000423    0.933333     0.966667\n",
       "3  0.001226    0.000391    0.900000     0.975000\n",
       "4  0.001214    0.000388    1.000000     0.958333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean times and scores:\n",
      " fit_time       0.001440\n",
      "score_time     0.000443\n",
      "test_score     0.960000\n",
      "train_score    0.963333\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "res_df = pd.DataFrame(res)\n",
    "display(res_df)\n",
    "\n",
    "print(\"Mean times and scores:\\n\", res_df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits of Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several benefits to using cross-validation instead of a single split into a training and a test set. First, remember that *train_test_split* performs a random split of the data. Imagine that we are “lucky” when randomly splitting the data, and all examples that are hard to classify end up in the training set. In that case, the test set will only contain “easy” examples, and our test set accuracy will be unrealistically high. Conversely, if we are “unlucky,” we might have randomly put all the hard-to-classify examples in the test set and consequently obtain an unrealistically low score. However, when using cross-validation, each example will be in the test set exactly once: each example is in one of the folds, and each fold is the test set once. Therefore, the model needs to generalize well to all of the samples in the dataset for all of the cross-validation scores (and their mean) to be high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having multiple splits of the data also provides some information about how sensitive our model is to the selection of the training dataset. For the *iris* dataset, we saw accuracies between 90% and 100%. This is quite a range, and it provides us with an idea about how the model might perform in the worst case and best case scenarios when applied to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another benefit of cross-validation as compared to using a single split of the data is that we use our data more effectively. When using train_test_split, we usually use 75% of the data for training and 25% of the data for evaluation. When using five-fold cross-validation, in each iteration we can use four-fifths of the data (80%) to fit the model. When using 10-fold cross-validation, we can use nine-tenths of the data (90%) to fit the model. More data will usually result in more accurate models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main disadvantage of cross-validation is increased computational cost. As we are now training k models instead of a single model, cross-validation will be roughly k times slower than doing a single split of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is important to keep in mind that cross-validation is not a way to build a model that can be applied to new data. Cross-validation does not return a model. When calling *cross_val_score*, multiple models are built internally, but the purpose of cross-validation is only to evaluate how well a given algorithm will generalize when trained on a specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
