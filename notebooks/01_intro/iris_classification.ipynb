{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "We assume we are a hobby botanist, and we are interested in distinguishing the species of iris flowers we have found.\n",
    "\n",
    "We have collected some measurements associated with each iris: the length and width of the petals and the length and width of the sepals, all measured in centimeters.\n",
    "\n",
    "We also have the measurements of some irises that have previously been identified by an expert botanist as belonging to the species *setosa*, *versicolor*, or *virginica*.  For our purposes, we'll assume that these are the only species we'll see in the wild.\n",
    "\n",
    "Our goal is to build a model so that we can predict the species of a new iris based on its measurements.  This is a *classification* problem, with the species of irises as the classes.  The desired output for a data point is the species of an iris.  For a particular data point, the species it belongs to is called its *label*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Data\n",
    "\n",
    "The data we'll use for this example is the Iris dataset, a classical dataset in machine learning and statistics.  The dataset is included in the *scikit-learn datasets* module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "from IPython.display import display\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of iris_dataset:\n",
      " dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "# Here are the keys of the iris Bunch object\n",
    "print(\"Keys of iris_dataset:\\n\", iris_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# The value of the 'DESCR' key is a short description of the dataset\n",
    "print(iris_dataset['DESCR'][:310] + \"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target names: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# The value of the 'target_names' key is an array of strings, containing \n",
    "#   the species we want to predict.\n",
    "print(\"Target names:\", iris_dataset['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names:\n",
      " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# The value of 'feature_names' is a list of strings, giving the \n",
    "#    description of each feature.\n",
    "print(\"Feature names:\\n\", iris_dataset['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# The data itself is contained in the 'target' and 'data' fields.\n",
    "#   'data' contains the numeric measurements.\n",
    "print(\"Type of data:\", type(iris_dataset['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of data:\", iris_dataset['data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five rows of data:\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "# Here are the feature values for the first 5 samples\n",
    "print(\"First five rows of data:\\n\", iris_dataset['data'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of target: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# The target array contains the species of each of the flowers that\n",
    "#   were measured, also as a Numpy array\n",
    "print(\"Type of target:\", type(iris_dataset['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of target: (150,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of target:\", iris_dataset['target'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# The species are encoded as integers from 0 to 2\n",
    "# The values are given by the 'target_names':\n",
    "#   0 = setosa\n",
    "#   1 = versicolor\n",
    "#   2 = virginica\n",
    "print(\"Target:\\n\", iris_dataset['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Success: Training and Testing Data\n",
    "\n",
    "To assess our model's performance, we show it data for which we have labels.  This is usually done by splitting the labeled data we have collected into 2 parts.  \n",
    "\n",
    "One part, which we use to build our model, is called the *training data* or *training set*.\n",
    "\n",
    "The other part, which we will use to assess how well the model works, is called the *test data* or *test set* or *hold-out set*.\n",
    "\n",
    "scikit-learn contains a function that shuffles the dataset and splits it for you, the *train_test_split* function.  This function extracts 75% of the rows as the training set, along with the labels for this data.  The remaining 25% is the test set.\n",
    "\n",
    "In scikit-learn, data is usually denoted with *X*, while labels are denoted by *y*.  This is inspired by the standard formula f(x)=y, where x is the input and y is the output.  We use a capital *X*, because the data is a 2D matrix, and we use a lowercase *y* because the target is a 1D vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data and assign the outputs\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_dataset['data'], iris_dataset['target'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_shape: (112, 4)\n",
      "y_train_shape: (112,)\n"
     ]
    }
   ],
   "source": [
    "# Training data shapes\n",
    "print(\"X_train_shape:\", X_train.shape)\n",
    "print(\"y_train_shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (38, 4)\n",
      "y_test_shape: (38,)\n"
     ]
    }
   ],
   "source": [
    "# Test data shapes\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test_shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Look at Our Data\n",
    "\n",
    "We want to take a quick look at our data to see if any abnormalities stick out to us.  One way to do this is to visualize it.\n",
    "\n",
    "Here, we'll create scatterplots between each 2 pairs of features (known as *pair plots*).  Note that this is a reasonable approach, because we only have 4 features, but it would not be reasonable for a much larger number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
