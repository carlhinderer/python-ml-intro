{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we’ve assumed that our data comes in as a two-dimensional array of floating-point numbers, where each column is a continuous feature that describes the data points. For many applications, this is not how the data is collected. A particularly common type of feature is the *categorical features*. Also known as *discrete features*, these are usually not numeric. \n",
    "\n",
    "The distinction between categorical features and continuous features is analogous to the distinction between classification and regression, only on the input side rather than the output side. Examples of continuous features that we have seen are pixel brightnesses and size measurements of plant flowers. Examples of categorical features are the brand of a product, the color of a product, or the department (books, clothing, hardware) it is sold in. These are all properties that can describe a product, but they don’t vary in a continuous way. A product belongs either in the clothing department or in the books department. There is no middle ground between books and clothing, and no natural order for the different categories (books is not greater or less than clothing, hardware is not between books and clothing, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we will use the dataset of adult incomes in the United States, derived from the 1994 census database. The task of the adult dataset is to predict whether a worker has an income of over $50,000 or under $50,000. The features in this dataset include the workers’ ages, how they are employed (self employed, private industry employee, government employee, etc.), their education, their gender, their working hours per week, occupation, and more. \n",
    "\n",
    "The table shows the first few entries in the dataset."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The first few entries in the adult dataset:\n",
    "\n",
    "   age \tworkclass \t     education   gender   hrs-per-week  occupation \t       income\n",
    "\n",
    "0  39   State-gov        Bachelors   Male     40            Adm-clerical       <=50K\n",
    "\n",
    "1  50   Self-emp-not-inc Bachelors   Male     13            Exec-managerial    <=50K\n",
    "\n",
    "2  38   Private          HS-grad     Male     40            Handlers-cleaners  <=50K\n",
    "\n",
    "3  53   Private          11th        Male     40            Handlers-cleaners  <=50K\n",
    "\n",
    "4  28   Private          Bachelors   Female   40            Prof-specialty     <=50K\n",
    "\n",
    "5  37   Private          Masters     Female   40            Exec-managerial    <=50K\n",
    "\n",
    "6  49   Private          9th         Female   16            Other-service      <=50K\n",
    "\n",
    "7  52   Self-emp-not-inc HS-grad     Male     45            Exec-managerial    >50K\n",
    "\n",
    "8  31   Private          Masters     Female   50            Prof-specialty     >50K\n",
    "\n",
    "9  42   Private          Bachelors   Male     40            Exec-managerial    >50K\n",
    "\n",
    "10 37   Private          Some-college Male    80            Exec-managerial    >50K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is phrased as a classification task with the two classes being income *<=50k* and *>50k*. It would also be possible to predict the exact income, and make this a regression task. However, that would be much more difficult, and the 50K division is interesting to understand on its own.\n",
    "\n",
    "In this dataset, *age* and *hours-per-week* are continuous features, which we know how to treat. The *workclass*, *education*, *sex*, and *occupation* features are categorical, however. All of them come from a fixed list of possible values, as opposed to a range, and denote a qualitative property, as opposed to a quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a starting point, let’s say we want to learn a logistic regression classifier on this data. We know from Chapter 2 that a logistic regression makes predictions, ŷ, using the following formula:\n",
    "\n",
    "    ŷ = w[0] * x[0] + w[1] * x[1] + ... + w[p] * x[p] + b > 0\n",
    "\n",
    "where w[i] and b are coefficients learned from the training set and x[i] are the input features. This formula makes sense when x[i] are numbers, but not when x[2] is \"Masters\" or \"Bachelors\". Clearly we need to represent our data in some different way when applying logistic regression. The next section will explain how we can overcome this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encoding (Dummy Variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By far the most common way to represent categorical variables is using the *one-hot-encoding* or *one-out-of-N encoding*, also known as *dummy variables*. The idea behind dummy variables is to replace a categorical variable with one or more new features that can have the values 0 and 1. The values 0 and 1 make sense in the formula for linear binary classification (and for all other models in scikit-learn), and we can represent any number of categories by introducing one new feature per category, as described here.\n",
    "\n",
    "Let’s say for the workclass feature we have possible values of \"Government Employee\", \"Private Employee\", \"Self Employed\", and \"Self Employed Incorporated\". To encode these four possible values, we create four new features, called \"Government Employee\", \"Private Employee\", \"Self Employed\", and \"Self Employed Incorporated\". A feature is 1 if workclass for this person has the corresponding value and 0 otherwise, so exactly one of the four new features will be 1 for each data point. This is why this is called one-hot or one-out-of-N encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The principle is illustrated in the following table. A single feature is encoded using four new features. When using this data in a machine learning algorithm, we would drop the original *workclass* feature and only keep the 0–1 features."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Encoding the workclass feature using one-hot encoding workclass:\n",
    "\n",
    "Government Employee  Private Employee  Self Employed  Self Employed Incorporated\n",
    "\n",
    "1                    0                 0              0\n",
    "\n",
    "0                    1                 0              0\n",
    "\n",
    "0                    0                 1              0\n",
    "\n",
    "0                    0                 0              1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "The one-hot encoding we use is quite similar, but not identical, to the dummy coding used in statistics. For simplicity, we encode each category with a different binary feature. In statistics, it is common to encode a categorical feature with k different possible values into k–1 features (the last one is represented as all zeros). This is done to simplify the analysis (more technically, this will avoid making the data matrix rank-deficient)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to convert your data to a one-hot encoding of categorical variables, using either pandas or scikit-learn. Let’s see how we can do it using pandas. We start by loading the data using pandas from a comma-separated values (CSV) file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "from IPython.display import display\n",
    "import mglearn\n",
    "\n",
    "# Don't display deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>occupation</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Male</td>\n",
       "      <td>13</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education   gender  hours-per-week  \\\n",
       "0   39          State-gov   Bachelors     Male              40   \n",
       "1   50   Self-emp-not-inc   Bachelors     Male              13   \n",
       "2   38            Private     HS-grad     Male              40   \n",
       "3   53            Private        11th     Male              40   \n",
       "4   28            Private   Bachelors   Female              40   \n",
       "\n",
       "           occupation  income  \n",
       "0        Adm-clerical   <=50K  \n",
       "1     Exec-managerial   <=50K  \n",
       "2   Handlers-cleaners   <=50K  \n",
       "3   Handlers-cleaners   <=50K  \n",
       "4      Prof-specialty   <=50K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# The file has no headers naming the columns, so we pass header=None\n",
    "# and provide the column names explicitly in \"names\"\n",
    "adult_path = os.path.join(mglearn.datasets.DATA_PATH, \"adult.data\")\n",
    "data = pd.read_csv(\n",
    "    adult_path, header=None, index_col=False,\n",
    "    names=['age', 'workclass', 'fnlwgt', 'education',  'education-num',\n",
    "           'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
    "           'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "           'income'])\n",
    "\n",
    "# For illustration purposes, we only select some of the columns\n",
    "data = data[['age', 'workclass', 'education', 'gender', 'hours-per-week',\n",
    "             'occupation', 'income']]\n",
    "\n",
    "# IPython.display allows nice output formatting within the Jupyter notebook\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
